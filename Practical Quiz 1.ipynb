{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COM6012 - 2017: Practical Quiz 1\n",
    "\n",
    "## Question 1 [2 marks]\n",
    "\n",
    "Use the dataset [Census Income Data](./files/CensusIncomeData.csv) to find out how many women have a Masters degree. Provide your solution in the Notebook.\n",
    "\n",
    "## Question 2 [3 marks]\n",
    "\n",
    "We will use the file \"TaleOfTwoCities.txt\" (available in Notebook 2, and also [here](./files/TaleOfTwoCities.txt)). Please build a pipeline to do the following \n",
    "\n",
    "1. Read the file in\n",
    "2. Tokenize it\n",
    "3. Remove stop words\n",
    "4. Map all words to lowercase\n",
    "5. Find the 15 most frequent words and the 15 least frequent words. Show them (30 words in total).\n",
    "\n",
    "The order of the above steps can be different but all should be included (and give the same results).\n",
    "\n",
    "Provide your solution in the Notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msparkVersion\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"2.0.1\"\u001b[0m\n",
       "\u001b[36mscalaVersion\u001b[0m: \u001b[32mString\u001b[0m = \u001b[32m\"2.11.8\"\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val sparkVersion = \"2.0.1\"\n",
    "val scalaVersion = scala.util.Properties.versionNumberString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 new artifact(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classpath.add(\n",
    "    \"org.apache.spark\" %% \"spark-yarn\" % sparkVersion,\n",
    "    \"org.apache.spark\" %% \"spark-mllib\" % sparkVersion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.SparkSession\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.functions.col\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.feature.Tokenizer\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.SparkSession._\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.sql.functions._\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.feature.NGram\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.{Pipeline, PipelineModel}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.feature.StopWordsRemover\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.spark.ml.{Pipeline, PipelineModel}\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions.col\n",
    "import org.apache.spark.ml.feature.Tokenizer\n",
    "import org.apache.spark.sql.SparkSession._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.ml.feature.NGram\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.apache.spark.ml.feature.StopWordsRemover\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Women that have a Masters Degree is: 420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mscala.io.Source\u001b[0m\n",
       "defined \u001b[32mobject \u001b[36mMasters\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "//Exercise 1\n",
    "import scala.io.Source\n",
    "\n",
    "\n",
    "object Masters {\n",
    "  def main(args: Array[String]) {\n",
    "      val sparkSession = SparkSession.builder\n",
    "        .master(\"local\")\n",
    "        .appName(\"Exercise_1\")\n",
    "        .getOrCreate()\n",
    "\n",
    "    val sc = sparkSession.sparkContext\n",
    "\n",
    "    val df = sparkSession.read\n",
    "            .format(\"com.databricks.spark.csv\")\n",
    "            .option(\"header\", \"false\") //reading the headers\n",
    "            .option(\"mode\", \"DROPMALFORMED\")\n",
    "            .load(\"files/CensusIncomeData.csv\");\n",
    "            \n",
    "      val selection = df.select(\"_c3\")\n",
    "      \n",
    "      //df.show()\n",
    "\n",
    "      //val counting_occurances = df.groupBy(\"_c3\").count().show()\n",
    "      \n",
    "      \n",
    "     val masters = df.filter(col(\"_c3\").like(\"%Masters\"))\n",
    "     val masters_women = masters.filter(col(\"_c9\") === \" Female\").count()\n",
    "    \n",
    "    \n",
    "     println(s\"The number of Women that have a Masters Degree is: $masters_women\")\n",
    "    \n",
    "   \n",
    "   }\n",
    "}\n",
    "Masters.main(Array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------+\n",
      "|extracted_words|most_frequent|\n",
      "+---------------+-------------+\n",
      "|               |           17|\n",
      "|            one|            5|\n",
      "|           year|            4|\n",
      "|           shot|            4|\n",
      "|          seven|            4|\n",
      "|          them,|            4|\n",
      "|       thousand|            4|\n",
      "|          large|            3|\n",
      "|        hundred|            3|\n",
      "|           now,|            3|\n",
      "|          fired|            3|\n",
      "|         light,|            2|\n",
      "|        burning|            2|\n",
      "|            jaw|            2|\n",
      "|         direct|            2|\n",
      "+---------------+-------------+\n",
      "only showing top 15 rows\n",
      "\n",
      "+---------------+--------------+\n",
      "|extracted_words|least_frequent|\n",
      "+---------------+--------------+\n",
      "|        present|             1|\n",
      "|       conceded|             1|\n",
      "|         worked|             1|\n",
      "|        snipped|             1|\n",
      "|       received|             1|\n",
      "|       spending|             1|\n",
      "|      character|             1|\n",
      "|         taking|             1|\n",
      "|          dozen|             1|\n",
      "|      countries|             1|\n",
      "|       chickens|             1|\n",
      "|           even|             1|\n",
      "|    rest--along|             1|\n",
      "|      cautioned|             1|\n",
      "|            got|             1|\n",
      "+---------------+--------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mobject \u001b[36mtales\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Exercise 2\n",
    "\n",
    "object tales {\n",
    "    def main() {\n",
    "        val sparkSession = SparkSession.builder\n",
    "            .master(\"local\")\n",
    "            .appName(\"Exercise_2\")\n",
    "            .getOrCreate()\n",
    "        \n",
    "        val sc = sparkSession.sparkContext  \n",
    "        \n",
    "        import sparkSession.implicits._\n",
    "\n",
    "        val tales = sparkSession.read.text(\"files/TaleOfTwoCities.txt\").as[String]\n",
    "        //tales.show()\n",
    "        \n",
    "        val tokenizer = new Tokenizer().setInputCol(\"value\").setOutputCol(\"tokens\")\n",
    "        val stop_word_remove = new StopWordsRemover().setInputCol(tokenizer.getOutputCol).setOutputCol(\"extracted_words\")\n",
    "        \n",
    "        val pipeline = new Pipeline().setStages(Array(tokenizer, stop_word_remove))\n",
    "        val model = pipeline.fit(tales)\n",
    "        val results = model.transform(tales)\n",
    "        \n",
    "        \n",
    "        val top = results.withColumn(\"extracted_words\", explode(col(\"extracted_words\")))\n",
    "        val most = top.groupBy(\"extracted_words\").agg(count(\"*\") as \"most_frequent\").orderBy(desc(\"most_frequent\")).show(15)\n",
    "        \n",
    "        val last = results.withColumn(\"extracted_words\", explode(col(\"extracted_words\")))\n",
    "        val least = last.groupBy(\"extracted_words\").agg(count(\"*\") as \"least_frequent\").orderBy(\"least_frequent\").show(15)\n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "tales.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
